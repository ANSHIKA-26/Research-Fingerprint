{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANSHIKA-26/Research-Fingerprint/blob/main/GAN_26_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itMapuVds9_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51afe890-28a3-424f-b1ba-14a3afecbc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGnIK8SjuYGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8971a628-8caf-40eb-83bf-66afbb46374e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piq\n",
            "  Downloading piq-0.8.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from piq) (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.10.0->piq) (2.0.2)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.10.0->piq) (2.9.0+cu126)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.10.0->piq) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision>=0.10.0->piq) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision>=0.10.0->piq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision>=0.10.0->piq) (3.0.3)\n",
            "Downloading piq-0.8.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: piq\n",
            "Successfully installed piq-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install piq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPsOL--guTqY"
      },
      "outputs": [],
      "source": [
        "import os, gc, torch, numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from piq import ssim as piqi_ssim, psnr as piqi_psnr\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VoIKeGUy3dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b508a332-7e02-4dc1-d0e0-648fb74de777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Paths ready\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/gan_2026\"\n",
        "\n",
        "DATA_ROOT = os.path.join(PROJECT_ROOT, \"GAN2_LOCAL\")\n",
        "TRAIN_ROOT = os.path.join(DATA_ROOT, \"train\")\n",
        "VAL_ROOT   = os.path.join(DATA_ROOT, \"val\")\n",
        "TEST_ROOT  = os.path.join(DATA_ROOT, \"test\")\n",
        "\n",
        "CHUNKS_ROOT = os.path.join(DATA_ROOT, \"chunks_train\")\n",
        "\n",
        "CKPT_DIR = os.path.join(PROJECT_ROOT, \"checkpoints\")\n",
        "LOG_DIR  = os.path.join(PROJECT_ROOT, \"logs\")\n",
        "SAMPLE_DIR = os.path.join(PROJECT_ROOT, \"samples\")\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(CKPT_DIR, \"latest.pth\")\n",
        "\n",
        "os.makedirs(CHUNKS_ROOT, exist_ok=True)\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Paths ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuDXtEzu_2nr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from piq import ssim as piqi_ssim, psnr as piqi_psnr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHTeIl5F_4oI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21310f11-35b1-48af-eb75-6bd2482e8a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# ===== DEVICE =====\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# ===== TRAINING CONSTANTS =====\n",
        "BATCH_SIZE = 32          # fixed as you wanted\n",
        "NUM_CHUNKS = 4\n",
        "EPOCHS_PER_CHUNK = 15\n",
        "CYCLES = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEK8F5UCdZHg"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, UnidentifiedImageError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IysH6CAC18-I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class PairedDataset(Dataset):\n",
        "    def __init__(self, root, size=128):\n",
        "        self.A_dir = os.path.join(root, \"A\")\n",
        "        self.B_dir = os.path.join(root, \"B\")\n",
        "\n",
        "        # keep only paired filenames\n",
        "        self.names = sorted([\n",
        "            f for f in os.listdir(self.A_dir)\n",
        "            if os.path.exists(os.path.join(self.B_dir, f))\n",
        "        ])\n",
        "\n",
        "        self.transform = T.Compose([\n",
        "            T.Grayscale(num_output_channels=1),  # üîπ force 1 channel\n",
        "            T.Resize((size, size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.5,), (0.5,))          # üîπ correct for grayscale\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        A_path = os.path.join(self.A_dir, name)\n",
        "        B_path = os.path.join(self.B_dir, name)\n",
        "\n",
        "        try:\n",
        "            A = Image.open(A_path).convert(\"RGB\")\n",
        "            B = Image.open(B_path).convert(\"RGB\")\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            print(f\"‚ö†Ô∏è Skipping corrupted image: {name}\")\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        return self.transform(A), self.transform(B), name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2IKMdSM2Beq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749e9c65-ae73-401c-cf25-ef9ea01cffcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples in chunk_0: 4900\n",
            "Latent shape: torch.Size([1, 128, 128])\n",
            "GT shape: torch.Size([1, 128, 128])\n",
            "Filename: 2302_11010.png\n"
          ]
        }
      ],
      "source": [
        "# quick test on one chunk\n",
        "test_dataset = PairedDataset(\n",
        "    os.path.join(CHUNKS_ROOT, \"chunk_0\")\n",
        ")\n",
        "\n",
        "print(\"Total samples in chunk_0:\", len(test_dataset))\n",
        "\n",
        "A, B, name = test_dataset[0]\n",
        "print(\"Latent shape:\", A.shape)\n",
        "print(\"GT shape:\", B.shape)\n",
        "print(\"Filename:\", name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FltGgnfV29vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8712d2c5-afa7-47f6-c243-2c7d123b10e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Effective batch size: 32\n"
          ]
        }
      ],
      "source": [
        "# ===== adaptive batch size (GPU safe + CPU safe) =====\n",
        "if DEVICE.type == \"cpu\":\n",
        "    EFFECTIVE_BATCH_SIZE = min(16, BATCH_SIZE)\n",
        "else:\n",
        "    EFFECTIVE_BATCH_SIZE = BATCH_SIZE\n",
        "\n",
        "print(\"Effective batch size:\", EFFECTIVE_BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQ48Qpv3Aod"
      },
      "outputs": [],
      "source": [
        "# ===== Train DataLoader (example: chunk_0) =====\n",
        "train_dataset = PairedDataset(\n",
        "    os.path.join(CHUNKS_ROOT, \"chunk_0\")\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=EFFECTIVE_BATCH_SIZE,\n",
        "    shuffle=True,        # important for GAN training\n",
        "    num_workers=0        # safest on Colab (CPU & GPU)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUxTP4RJ3DMU"
      },
      "outputs": [],
      "source": [
        "# ===== Validation DataLoader (full validation set) =====\n",
        "val_dataset = PairedDataset(VAL_ROOT)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=EFFECTIVE_BATCH_SIZE,\n",
        "    shuffle=False,       # NEVER shuffle validation\n",
        "    num_workers=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qBNl1hf3GlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4bef18-35b0-49ec-91e3-ce5dcacc9f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batch shape A: torch.Size([32, 1, 128, 128])\n",
            "Train batch shape B: torch.Size([32, 1, 128, 128])\n",
            "First filename: 2484_6269.png\n"
          ]
        }
      ],
      "source": [
        "# one batch sanity check\n",
        "A, B, names = next(iter(train_loader))\n",
        "\n",
        "print(\"Train batch shape A:\", A.shape)\n",
        "print(\"Train batch shape B:\", B.shape)\n",
        "print(\"First filename:\", names[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qbXOFIL35H3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f06cb7c-138d-45f3-e568-ea17b07247a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/photosynthesis-team/photosynthesis.metrics/releases/download/v0.4.0/lpips_weights.pt\" to /root/.cache/torch/hub/checkpoints/lpips_weights.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# MODEL ARCHITECTURE (UNCHANGED)\n",
        "# ===============================\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, i, o, stride=1):\n",
        "        super().__init__()\n",
        "        self.c1 = nn.Conv2d(i, o, 3, stride=stride, padding=1)\n",
        "        self.n1 = nn.InstanceNorm2d(o)\n",
        "        self.c2 = nn.Conv2d(o, o, 3, padding=1)\n",
        "        self.n2 = nn.InstanceNorm2d(o)\n",
        "        self.skip = nn.Conv2d(i, o, 1, stride=stride) if i != o or stride != 1 else nn.Identity()\n",
        "        self.relu = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r = self.skip(x)\n",
        "        x = self.relu(self.n1(self.c1(x)))\n",
        "        x = self.n2(self.c2(x))\n",
        "        return self.relu(x + r)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, i, o):\n",
        "        super().__init__()\n",
        "        self.block = ResBlock(i, o, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s = self.block(x)\n",
        "        return s, s\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, i, skip, o):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(i, o, 2, stride=2)\n",
        "        self.block = ResBlock(o + skip, o)\n",
        "\n",
        "    def forward(self, x, s):\n",
        "        x = self.up(x)\n",
        "        if x.shape[-1] != s.shape[-1]:\n",
        "            s = F.interpolate(s, (x.shape[-2], x.shape[-1]))\n",
        "        return self.block(torch.cat([x, s], 1))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = 64\n",
        "        self.in_conv = nn.Conv2d(1, base, 1)\n",
        "\n",
        "        self.d0 = Down(base, base * 2)\n",
        "        self.d1 = Down(base * 2, base * 4)\n",
        "        self.d2 = Down(base * 4, base * 8)\n",
        "        self.d3 = Down(base * 8, base * 16)\n",
        "\n",
        "        self.bottle = ResBlock(base * 16, base * 32)\n",
        "\n",
        "        self.u3 = Up(base * 32, base * 16, base * 16)\n",
        "        self.u2 = Up(base * 16, base * 8, base * 8)\n",
        "        self.u1 = Up(base * 8, base * 4, base * 4)\n",
        "        self.u0 = Up(base * 4, base * 2, base * 2)\n",
        "\n",
        "        self.out = nn.Conv2d(base * 2, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, s0 = self.d0(self.in_conv(x))\n",
        "        x, s1 = self.d1(x)\n",
        "        x, s2 = self.d2(x)\n",
        "        x, s3 = self.d3(x)\n",
        "\n",
        "        x = self.bottle(x)\n",
        "\n",
        "        x = self.u3(x, s3)\n",
        "        x = self.u2(x, s2)\n",
        "        x = self.u1(x, s1)\n",
        "        x = self.u0(x, s0)\n",
        "\n",
        "        return self.out(x)\n",
        "\n",
        "\n",
        "class MultiScaleD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = 64\n",
        "        layers = []\n",
        "\n",
        "        for i, o in [(2, base), (base, base * 2), (base * 2, base * 4), (base * 4, base * 8)]:\n",
        "            layers += [\n",
        "                nn.Conv2d(i, o, 4, 2, 1),\n",
        "                nn.InstanceNorm2d(o),\n",
        "                nn.LeakyReLU(0.2)\n",
        "            ]\n",
        "\n",
        "        self.trunk = nn.Sequential(*layers)\n",
        "        self.h1 = nn.Conv2d(base * 8, 1, 1)\n",
        "        self.h2 = nn.Conv2d(base * 8, 1, 1)\n",
        "        self.h3 = nn.Conv2d(base * 8, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.trunk(x)\n",
        "        return [\n",
        "            self.h1(f),\n",
        "            self.h2(F.avg_pool2d(f, 2)),\n",
        "            self.h3(F.avg_pool2d(f, 4))\n",
        "        ]\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# LOSS FUNCTION (UNCHANGED)\n",
        "# ===============================\n",
        "\n",
        "from piq import LPIPS\n",
        "LPIPS_MODEL = LPIPS().to(DEVICE).eval()\n",
        "\n",
        "class GANLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.L1Loss()\n",
        "\n",
        "    def forward(self, real, fake, dFake, dReal):\n",
        "        lp = LPIPS_MODEL(fake, real).mean()\n",
        "\n",
        "        adv = (\n",
        "            sum(F.mse_loss(h, torch.zeros_like(h)) for h in dFake) +\n",
        "            sum(F.mse_loss(h, torch.ones_like(h)) for h in dReal)\n",
        "        )\n",
        "\n",
        "        return adv + 10 * self.l1(fake, real) + 0.05 * lp, {\n",
        "            \"Adv\": adv.item(),\n",
        "            \"LPIPS\": lp.item()\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ew4HfaB395T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1718ed-3f0e-42bb-e7cc-57cb56317d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Generator'>\n",
            "<class '__main__.MultiScaleD'>\n",
            "<class '__main__.GANLoss'>\n"
          ]
        }
      ],
      "source": [
        "print(Generator)\n",
        "print(MultiScaleD)\n",
        "print(GANLoss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA9111uC3UWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2bf67fb-1ca8-4559-a5b6-088321940738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator and Discriminator created.\n"
          ]
        }
      ],
      "source": [
        "# ===== Instantiate models =====\n",
        "G = Generator().to(DEVICE)\n",
        "D = MultiScaleD().to(DEVICE)\n",
        "\n",
        "print(\"Generator and Discriminator created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFx8Agxl4KR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218e8177-9919-4c15-fe6e-512f12b4d309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Optimizers created\n"
          ]
        }
      ],
      "source": [
        "# ===== optimizers =====\n",
        "optG = optim.Adam(\n",
        "    G.parameters(),\n",
        "    lr=2e-5,\n",
        "    betas=(0.5, 0.999)\n",
        ")\n",
        "\n",
        "optD = optim.Adam(\n",
        "    D.parameters(),\n",
        "    lr=2e-4,\n",
        "    betas=(0.5, 0.999)\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Optimizers created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVOy9cYg4M3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9ffcfc-3f75-4e46-b7f1-4ff1f2b9bc40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loss function ready\n"
          ]
        }
      ],
      "source": [
        "# ===== loss function =====\n",
        "loss_fn = GANLoss().to(DEVICE)\n",
        "print(\"‚úÖ Loss function ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e4Ryqh54PkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c48555-4327-4bfe-dae4-f0108f6bceec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G device: cuda:0\n",
            "D device: cuda:0\n",
            "Generator parameters: 129,764,737\n",
            "Discriminator parameters: 2,757,059\n"
          ]
        }
      ],
      "source": [
        "print(\"G device:\", next(G.parameters()).device)\n",
        "print(\"D device:\", next(D.parameters()).device)\n",
        "\n",
        "g_params = sum(p.numel() for p in G.parameters())\n",
        "d_params = sum(p.numel() for p in D.parameters())\n",
        "\n",
        "print(f\"Generator parameters: {g_params:,}\")\n",
        "print(f\"Discriminator parameters: {d_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCeFlzme45OM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90aa708f-5926-4f93-f451-7c43fc0e7de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ RESUME MODE\n",
            "Continuing from ‚Üí Cycle 1, Chunk 0, Epoch 6\n"
          ]
        }
      ],
      "source": [
        "start_cycle = 0\n",
        "start_chunk = 0\n",
        "start_epoch = 0\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "\n",
        "    # restore weights\n",
        "    G.load_state_dict(ckpt[\"G\"])\n",
        "    D.load_state_dict(ckpt[\"D\"])\n",
        "    optG.load_state_dict(ckpt[\"optG\"])\n",
        "    optD.load_state_dict(ckpt[\"optD\"])\n",
        "\n",
        "    # restore training position\n",
        "    start_cycle = ckpt[\"cycle\"]\n",
        "    start_chunk = ckpt[\"chunk\"]\n",
        "    start_epoch = ckpt[\"epoch\"] + 1  # resume from NEXT epoch\n",
        "\n",
        "    # ---- if epoch finished, move to next chunk ----\n",
        "    if start_epoch >= EPOCHS_PER_CHUNK:\n",
        "        start_epoch = 0\n",
        "        start_chunk += 1\n",
        "\n",
        "    # ---- if chunk finished, move to next cycle ----\n",
        "    if start_chunk >= NUM_CHUNKS:\n",
        "        start_chunk = 0\n",
        "        start_cycle += 1\n",
        "\n",
        "    print(\n",
        "        \"üîÑ RESUME MODE\\n\"\n",
        "        f\"Continuing from ‚Üí Cycle {start_cycle}, \"\n",
        "        f\"Chunk {start_chunk}, Epoch {start_epoch}\"\n",
        "    )\n",
        "else:\n",
        "    print(\"üÜï No checkpoint found ‚Üí Starting fresh training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jITA6K8r7zWh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def epoch_median_ssim(fake, real, k=5):\n",
        "    \"\"\"\n",
        "    fake, real: [B, 1, H, W] in range [-1, 1]\n",
        "    returns median SSIM over k random samples\n",
        "    \"\"\"\n",
        "    b = fake.size(0)\n",
        "    k = min(k, b)\n",
        "\n",
        "    idx = random.sample(range(b), k)\n",
        "\n",
        "    fake_sel = fake[idx]\n",
        "    real_sel = real[idx]\n",
        "\n",
        "    # convert [-1,1] ‚Üí [0,1] and CLAMP\n",
        "    fake_sel = ((fake_sel + 1) / 2).clamp(0.0, 1.0)\n",
        "    real_sel = ((real_sel + 1) / 2).clamp(0.0, 1.0)\n",
        "\n",
        "    ssim_vals = piqi_ssim(fake_sel, real_sel, reduction='none')\n",
        "    return torch.median(ssim_vals).item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAr4DUQu5cNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc284692-fefb-4140-e13a-95cb0e283b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¶ Cycle 1, Chunk 0\n",
            "\n",
            "üîÅ Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 81/154 [14:19<11:33,  9.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [24:53<00:00,  9.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 6 summary | Median SSIM (5-sample) = 0.6682\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=6)\n",
            "\n",
            "üîÅ Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 104/154 [04:50<02:01,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:49<00:00,  2.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 7 summary | Median SSIM (5-sample) = 0.6637\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=7)\n",
            "\n",
            "üîÅ Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 144/154 [06:18<00:23,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:40<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 8 summary | Median SSIM (5-sample) = 0.6717\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=8)\n",
            "\n",
            "üîÅ Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 108/154 [04:56<01:50,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:45<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 9 summary | Median SSIM (5-sample) = 0.6782\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=9)\n",
            "\n",
            "üîÅ Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|‚ñà‚ñç        | 23/154 [01:33<05:21,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:45<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 10 summary | Median SSIM (5-sample) = 0.6666\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=10)\n",
            "\n",
            "üîÅ Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 67/154 [03:20<03:32,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:49<00:00,  2.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 11 summary | Median SSIM (5-sample) = 0.6776\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=11)\n",
            "\n",
            "üîÅ Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 90/154 [04:15<02:36,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:47<00:00,  2.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 12 summary | Median SSIM (5-sample) = 0.6854\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=12)\n",
            "\n",
            "üîÅ Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 102/154 [04:37<02:02,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipping corrupted image: 2415_18790.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 154/154 [06:39<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Epoch 13 summary | Median SSIM (5-sample) = 0.6771\n",
            "üíæ Overwriting latest.pth (cycle=1, chunk=0, epoch=13)\n",
            "\n",
            "üîÅ Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|‚ñé         | 5/154 [00:12<05:54,  2.38s/it]"
          ]
        }
      ],
      "source": [
        "for cycle in range(start_cycle, CYCLES):\n",
        "\n",
        "    for chunk in range(NUM_CHUNKS):\n",
        "\n",
        "        if cycle == start_cycle and chunk < start_chunk:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nüì¶ Cycle {cycle}, Chunk {chunk}\")\n",
        "\n",
        "        train_dataset = PairedDataset(\n",
        "            os.path.join(CHUNKS_ROOT, f\"chunk_{chunk}\")\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=EFFECTIVE_BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=0\n",
        "        )\n",
        "\n",
        "        for epoch in range(EPOCHS_PER_CHUNK):\n",
        "\n",
        "            if (\n",
        "                cycle == start_cycle and\n",
        "                chunk == start_chunk and\n",
        "                epoch < start_epoch\n",
        "            ):\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nüîÅ Epoch {epoch}\")\n",
        "\n",
        "            G.train()\n",
        "            D.train()\n",
        "\n",
        "            epoch_ssim_vals = []   # ‚Üê collect SSIMs for this epoch\n",
        "\n",
        "            for A, B, _ in tqdm(train_loader):\n",
        "                A = A.to(DEVICE)\n",
        "                B = B.to(DEVICE)\n",
        "\n",
        "                # -------- Train Discriminator --------\n",
        "                optD.zero_grad()\n",
        "\n",
        "                fake = G(A).detach()\n",
        "\n",
        "                lossD = 0.5 * (\n",
        "                    sum(F.mse_loss(h, torch.ones_like(h))\n",
        "                        for h in D(torch.cat([A, B], 1))) +\n",
        "                    sum(F.mse_loss(h, torch.zeros_like(h))\n",
        "                        for h in D(torch.cat([A, fake], 1)))\n",
        "                )\n",
        "\n",
        "                lossD.backward()\n",
        "                optD.step()\n",
        "\n",
        "                # -------- Train Generator --------\n",
        "                optG.zero_grad()\n",
        "\n",
        "                fake = G(A)\n",
        "                lossG, _ = loss_fn(\n",
        "                    B,\n",
        "                    fake,\n",
        "                    D(torch.cat([A, fake], 1)),\n",
        "                    D(torch.cat([A, B], 1))\n",
        "                )\n",
        "\n",
        "                lossG.backward()\n",
        "                optG.step()\n",
        "\n",
        "                # ---- epoch-level SSIM (5 random samples) ----\n",
        "                with torch.no_grad():\n",
        "                    ssim_val = epoch_median_ssim(fake, B, k=5)\n",
        "                    epoch_ssim_vals.append(ssim_val)\n",
        "\n",
        "            # ---- epoch summary ----\n",
        "            epoch_ssim = np.median(epoch_ssim_vals)\n",
        "            print(\n",
        "                f\"üìä Epoch {epoch} summary | \"\n",
        "                f\"Median SSIM (5-sample) = {epoch_ssim:.4f}\"\n",
        "            )\n",
        "\n",
        "            # -------- SAVE CHECKPOINT --------\n",
        "            torch.save({\n",
        "                \"cycle\": cycle,\n",
        "                \"chunk\": chunk,\n",
        "                \"epoch\": epoch,\n",
        "                \"G\": G.state_dict(),\n",
        "                \"D\": D.state_dict(),\n",
        "                \"optG\": optG.state_dict(),\n",
        "                \"optD\": optD.state_dict()\n",
        "            }, CHECKPOINT_PATH)\n",
        "\n",
        "            print(\n",
        "                f\"üíæ Overwriting latest.pth \"\n",
        "                f\"(cycle={cycle}, chunk={chunk}, epoch={epoch})\"\n",
        "            )\n",
        "\n",
        "        # -------- VALIDATION (whole set, MEDIAN) --------\n",
        "        print(\"üîç Running validation...\")\n",
        "\n",
        "        G.eval()\n",
        "        ssim_vals, psnr_vals = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for A, B, _ in val_loader:\n",
        "                A = A.to(DEVICE)\n",
        "                B = B.to(DEVICE)\n",
        "\n",
        "                fake = ((G(A) + 1) / 2).clamp(0.0, 1.0)\n",
        "                real = ((B + 1) / 2).clamp(0.0, 1.0)\n",
        "\n",
        "                ssim_batch = piqi_ssim(fake, real, reduction='none')\n",
        "                psnr_batch = piqi_psnr(fake, real, reduction='none')\n",
        "\n",
        "                ssim_vals.extend(ssim_batch.cpu().numpy())\n",
        "                psnr_vals.extend(psnr_batch.cpu().numpy())\n",
        "\n",
        "        print(\n",
        "            f\"‚úÖ Validation result | \"\n",
        "            f\"Median SSIM = {np.median(ssim_vals):.4f}, \"\n",
        "            f\"Median PSNR = {np.median(psnr_vals):.2f}\"\n",
        "        )\n",
        "\n",
        "        gc.collect()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}